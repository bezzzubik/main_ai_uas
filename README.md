 # Технологический комплекс бортовой детекции скота для БАС

Технологический комплекс для обнаружения и отслеживания скота с борта БАС.

##  Описание проекта

Проект реализует модель компьютерного зрения для обнаружения крупного рогатого скота на изображениях и видео с использованием архитектуры нейронной сети YOLOv11 на базе беспилотника Skyris техник про.

## Состав команды

| Имя | Роль | Контакты |
|-----|------|----------|
| Ботвинов Кирилл Игоревич (Ростех)| ML-инженер | kirill.botvinoff@yandex.ru |
| Николайчук Дмитрий Сергеевич (Ростех)| DevOps-инженер | dimanchig90@gmail.com |
| Кувшинников Дмитрий Алексеевич (Ростех)| QA-тестировщик | 75dk7575@gmail.com|
| Рыбаков Тихон Тихонович (НИЯУ МИФИ)| QA-тестировщик | endlessnotenough@yandex.ru |


##  Архитектура модели

### YOLOv11 (You Only Look Once v11)
YOLOv1 - это современная модель реального времени для детекции объектов, разработанная Ultralytics.

#### Ключевые особенности архитектуры:
- **Backbone**: CSPDarknet (Cross Stage Partial Network)
- **Neck**: PAN-FPN (Path Aggregation Network - Feature Pyramid Network)
- **Head**: Anchor-free detection head

#### Основные компоненты:

1. **Backbone (CSPDarknet)**
   - Извлечение признаков из входного изображения
   - Использует CSP (Cross Stage Partial) соединения для улучшения градиентного потока
   - Эффективная архитектура с уменьшением разрешения и увеличением количества каналов

2. **Neck (PAN-FPN)**
   - PAN (Path Aggregation Network) для улучшения распространения информации
   - FPN (Feature Pyramid Network) для многомасштабного детектирования
   - Объединение признаков разных уровней для детекции объектов разного размера

3. **Head (Anchor-free)**
   - Anchor-free подход вместо anchor boxes
   - Прямое предсказание bounding boxes
   - Упрощение pipeline и улучшение производительности

##  Технические характеристики

### Параметры обучения:
```python
- Модель: YOLOv8n (nano version)
- Размер изображения: 640x640 пикселей
- Batch size: 16
- Learning rate: 0.01
- Epochs: 100
- Patience: 10 (ранняя остановка)
- Device: GPU (если доступен) 
```
## Разработка 

На первом этапе мы решили задачу передачи видеопотока в реальном времени.

### Использованное оборудование

1. **квадрокоптер с камерой**:
2. **ноутбук оператора на котором реализуется данный алгоритм**:

### Реализация 
Мы настроили прямую трансляцию видео с камеры дрона на ноутбук по Wi-Fi. Ноутбук выступил в роли сервера, который принимает поток и подготавливает его для дальнейшей обработки. Это позволило нам иметь полный контроль над данными. Также данный технологический комплекс реализуется на плате rasbpery pi, находящуюся в дроне. 

### Обработка картинки на удаленном сервере
Мы сконцентрировались на бработке данных на сервере из-за ограниченных вычислительных ресурсов платы rasbpery pi. Это дало несколько преимуществ:
1. **Мощность**: Сервер обладает высокопроизводительными GPU, что критически важно для быстрого выполнения нейросетевых алгоритмов

2. **Масштабируемость**: К одному серверу могут подключаться несколько дронов одновременно.

3. **Гибкость**: Легко обновлять и дообучать модели на сервере без изменения прошивок на дроне.
 
 ##  Список используемых ПО 
 в данном проекте было использовано такое ПО как:
 1. **ROS (Robot Operating System)** — это экосистема для программирования роботов, предоставляющая функциональность для распределённой работы. 

 1. **Python**—  высокоуровневый, интерпретируемый язык программирования ддя обучения ИИ модели. 

 2. **Bash**—  командная оболочка для Unix-подобных операционных систем (Linux, macOS), которая позволяет пользователям управлять системой через терминал с помощью текстовых команд
 


 Также для реализации обучения ИИ модели понадобились библиотеки Python:
 1. **OpenCV**—  библиотека с открытым исходным кодом для компьютерного зрения, машинного обучения и обработки изображений
 2. **YOLO**—  эффективный алгоритм, который позволяет выделять объекты на изображении

Разработанный программный комплекс может быть развернут на следующих операционных системах со стороны:
1. Сервера в любой **debian-based UIX системе** 
2. БВС на raspberry PI OS 

## Дальнейшее развитие проекта
Наш текущий прототип — это основа для более сложной системы. Планируемые направления развития:
1. **Детекция аномалий**: Обучение модели определять не только наличие, но и состояние животных (например, лежащие коровы, признаки болезней, подозрительное поведение).
2. **Модернизация модели компьютерного зрения** для бортового компьютер дрона с целью обеспечить автономную работу в условиях отсутствия стабильного соединения.
3. **Интеграция с GIS**: Наложение данных о количестве и перемещении скота на карту местности для анализа эффективности эксплуатации пастбищ. Пример: в будущем возможно будет оценить неиспользуемые территории и сменить назначение.
4. **автоматизация полета**: необходима для повышение эффективности и Снижение затрат